{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3a9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from monster.import_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d69ce",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3174951",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing data\n",
    "#\n",
    "\n",
    "# motifs\n",
    "lst_motifs = import_list_motifs('../data/lst_motifs')\n",
    "df_motifs_features = pd.read_csv('df_motifs_features.tsv')\n",
    "df_clusters = pd.read_csv('df_motifs_CLUMPs_standard_scaling.tsv')\n",
    "\n",
    "# positive dataset\n",
    "seqs_path_pos = '../data/datasets/minc_nr_positive_dataset.fasta'\n",
    "pos_dict = import_fasta_sequences_as_dict(seqs_path_pos)\n",
    "pos_dset_feat = pd.read_csv('df_pos_features.tsv')\n",
    "\n",
    "# negative dataset\n",
    "seqs_path_neg = '../data/datasets/minc_nr_negative_dataset.fasta'\n",
    "neg_dict = import_fasta_sequences_as_dict(seqs_path_neg)\n",
    "neg_dset_feat = pd.read_csv('df_neg_features.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5306850",
   "metadata": {},
   "source": [
    "# Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd4da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input_data(df_motifs_features, df_clusters,\n",
    "    pos_dset_feat, neg_dset_feat):\n",
    "    \"\"\"format_input_data\n",
    "       -----------------\n",
    "       This function formats input data in the correct\n",
    "       way for it to work with the following functions.\n",
    "       \n",
    "       Arguments:\n",
    "       df_motifs_features -- pandas dataframe with data of\n",
    "                             feature values of the motifs, but no\n",
    "                             information about the CLUMPs\n",
    "       df_clusters -- pandas dataframe of the motif and corresponding CLUMP\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset\n",
    "\n",
    "       Output:\n",
    "       df_all_motifs_all_features -- pandas dataframe with data of\n",
    "                                     feature values of the motifs\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset\n",
    "    \"\"\"\n",
    "    df_motifs_features.rename(columns = {'id' : 'motif'}, inplace = True)\n",
    "    df_all_motifs_all_features = df_clusters.merge(df_motifs_features)\n",
    "    pos_dset_feat.drop(columns = 'id', inplace = True)\n",
    "    neg_dset_feat.drop(columns = 'id', inplace = True)\n",
    "    \n",
    "    return df_all_motifs_all_features, pos_dset_feat, neg_dset_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9c098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_motifs_all_features, pos_dset_feat, neg_dset_feat = format_input_data(df_motifs_features, df_clusters, pos_dset_feat, neg_dset_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab8b2a",
   "metadata": {},
   "source": [
    "# occ_each_mot_in_each_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfe6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_position(lst_motifs, dict_seqs, dataset):\n",
    "    \"\"\"start_end_position\n",
    "       ------------------\n",
    "       This function calculates the start and end position \n",
    "       of the motifs in the sequences.\n",
    "       \n",
    "       Arguments:\n",
    "       lst_motifs -- list of motifs\n",
    "       dict_seqs -- dictionary of fasta sequences where the key is the\n",
    "                    id and the value is the sequence\n",
    "       dataset -- 'positive' or 'negative'\n",
    "       \n",
    "       Output:\n",
    "       df_start_end_position -- pandas dataframe where:\n",
    "                                first column is the motif\n",
    "                                second column is the sequence id\n",
    "                                third column is the start position\n",
    "                                fourth column is the end position\n",
    "                    \n",
    "    \"\"\"\n",
    "    \n",
    "    lst_dict = [] \n",
    "    \n",
    "    # Iterate the list of motifs\n",
    "    # For each motif, go through the dictionary of sequences,\n",
    "    for motif in lst_motifs:\n",
    "            for seq_id in dict_seqs:\n",
    "                # Assign the sequence to the variable record\n",
    "                record = dict_seqs[seq_id]\n",
    "                # Run the finditer (to find the start and end positions)\n",
    "                for match in re.finditer(motif, record):\n",
    "                    # append the motif, the sequence id, \n",
    "                    # the start and end position to the list.\n",
    "                    lst_dict.append({'motif':motif, 'seq_id':seq_id, \n",
    "                                     'start':match.start(), 'end':match.end()})\n",
    "    df_start_end_position = pd.DataFrame(lst_dict)\n",
    "    df_start_end_position['dataset'] = dataset\n",
    "    \n",
    "    return df_start_end_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792d7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occ_each_mot_in_each_seq(df_start_end_position, dataset):\n",
    "    \"\"\"occ_each_mot_in_each_seq\n",
    "       ------------------------\n",
    "       This function calculates the occurrences\n",
    "       of each motif in each sequence.\n",
    "       \n",
    "       Arguments: \n",
    "       df_start_end_position -- pandas dataframe where:\n",
    "                                first column is the motif\n",
    "                                second column is the sequence id\n",
    "                                third column is the start position\n",
    "                                fourth column is the end position\n",
    "       dataset -- 'positive' or 'negative'\n",
    "\n",
    "       Output:\n",
    "       df_occ_seq -- pandas dataframe where: \n",
    "                     first column is the motif\n",
    "                     second column is the sequence id \n",
    "                     third column is the number of occurrences\n",
    "                     fourth column is the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    df_occ_seq = df_start_end_position.groupby(\n",
    "        ['motif','seq_id']).size().reset_index(name='occ') \n",
    "    \n",
    "    df_occ_seq['dataset'] = dataset\n",
    "    \n",
    "    if df_occ_seq.shape == df_occ_seq.drop_duplicates().shape:\n",
    "        return df_occ_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316b5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_occs_mots_CLUMPs_both_dsets(df_start_end_position_pos, \n",
    "                                   df_start_end_position_neg, df_clusters):\n",
    "    \"\"\"df_occs_mots_CLUMPs_both_dsets\n",
    "       ------------------------------\n",
    "       This function gathers information of the occurrences\n",
    "       of each motif in each sequence in each dataset, and of \n",
    "       the corresponding CLUMP.\n",
    "       \n",
    "       Arguments:\n",
    "       df_start_end_position_pos -- pandas dataframe where:\n",
    "                                    first column is the motif\n",
    "                                    second column is the sequence id\n",
    "                                    third column is the start position\n",
    "                                    fourth column is the end position\n",
    "       df_start_end_position_neg -- pandas dataframe where:\n",
    "                                    first column is the motif\n",
    "                                    second column is the sequence id\n",
    "                                    third column is the start position\n",
    "                                    fourth column is the end position\n",
    "       df_clusters -- pandas dataframe of the motif and corresponding CLUMP\n",
    "       \n",
    "       Output:\n",
    "       df_general -- pandas dataframe with: motif, CLUMP, seq_id, occ, dataset\n",
    "    \"\"\"\n",
    "    df_occ_seq_pos = occ_each_mot_in_each_seq(\n",
    "        df_start_end_position_pos, \"positive\")\n",
    "    df_occ_seq_neg = occ_each_mot_in_each_seq(\n",
    "        df_start_end_position_neg, \"negative\")   \n",
    "    \n",
    "    df_clusters.rename(columns = {'id' : 'motif'}, inplace = True)\n",
    "    df_general = pd.concat(\n",
    "        [pd.merge(df_clusters, df_occ_seq_pos, on='motif'), \n",
    "         pd.merge(df_clusters, df_occ_seq_neg, on='motif')])\n",
    "    \n",
    "    return df_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c40daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occurrences_of_mots_in_datasets(df_clusters, pos_dict, neg_dict):\n",
    "    \"\"\"find_occurrences_of_mots_in_datasets\n",
    "       ------------------------------------\n",
    "       This function finds the occurrences of motifs of CLUMPs \n",
    "       in the positive and negative datasets, by finding their\n",
    "       start and end position. It then combines the information\n",
    "       in a pandas dataframe.\n",
    "       \n",
    "       Arguments:\n",
    "       df_clusters -- pandas dataframe of the motif and corresponding CLUMP\n",
    "       pos_dict -- dictionary of fasta sequences where the key is the\n",
    "                   id and the value is the sequence of positive dataset\n",
    "       neg_dict -- dictionary of fasta sequences where the key is the\n",
    "                   id and the value is the sequence of negative dataset\n",
    "       \n",
    "       Output:\n",
    "       df_general -- pandas dataframe with: motif, CLUMP, seq_id, occ, dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    lst_motifs = list(df_clusters.motif)\n",
    "    \n",
    "    df_start_end_position_pos = start_end_position(\n",
    "        lst_motifs, pos_dict, 'positive')\n",
    "    df_start_end_position_neg = start_end_position(\n",
    "        lst_motifs, neg_dict, 'negative')\n",
    "    \n",
    "    df_general = df_occs_mots_CLUMPs_both_dsets(df_start_end_position_pos,\n",
    "                                                df_start_end_position_neg, \n",
    "                                                df_clusters)\n",
    "    \n",
    "    return df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd230c",
   "metadata": {},
   "source": [
    "# non_redundant_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69896e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_extended_motifs(lst_motifs):\n",
    "    \"\"\"find_extended_motifs\n",
    "       --------------------\n",
    "       This function identifies extended motifs in CLUMPs.\n",
    "       \n",
    "       Arguments:\n",
    "       lst_motifs -- list of motifs\n",
    "       \n",
    "       Output: \n",
    "       lst_all_extended_motifs -- ???????\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_extended_motifs = {}\n",
    "    lst_motifs = sorted(lst_motifs, key=len)\n",
    "    print(lst_motifs)\n",
    "    lst_known_motifs = []\n",
    "    lst_all_extended_motifs = []\n",
    "    for motif in lst_motifs:\n",
    "        if motif not in lst_known_motifs:\n",
    "            lst_extended_motifs = [\n",
    "                m for m in lst_motifs if motif in m and motif != m]\n",
    "            lst_known_motifs.append(motif)\n",
    "            lst_known_motifs+=lst_extended_motifs\n",
    "            if len(lst_extended_motifs)>0:\n",
    "                lst_all_extended_motifs+=[[motif]+lst_extended_motifs]\n",
    "                \n",
    "    return lst_all_extended_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4c1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_redundant_motifs(df_clusters, df_general):\n",
    "    \"\"\"non_redundant_motifs\n",
    "       --------------------\n",
    "       This function identifies non redundant extended motifs.\n",
    "       Non redundant motifs (e.g. root motifs and non-extended motifs) \n",
    "       are stored in a list called lst_motifs_mask.\n",
    "       \n",
    "       Arguments:\n",
    "       df_clusters -- pandas dataframe of the motif and corresponding CLUMP.\n",
    "       df_general -- pandas dataframe with: motif, CLUMP, seq_id, occ, dataset\n",
    "       \n",
    "       Output:\n",
    "       lst_motifs_mask -- list of non redundant motifs.\n",
    "       df_general_non_redundant -- pandas dataframe where the occurrences\n",
    "       belong only to the non redundant motifs\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    lst_motifs = list(df_clusters.motif)\n",
    "    \n",
    "    lst_motifs_mask = []\n",
    "    for c in df_clusters.CLUMP.unique():\n",
    "        lst_motifs = df_clusters.loc[\n",
    "            df_clusters.CLUMP==c, 'motif'].unique()\n",
    "        print('--------------------------------------')\n",
    "        print(f\"CLUMP {c} :\")\n",
    "        lst_ext_motifs = find_extended_motifs(lst_motifs)\n",
    "        lst_all_ext_motifs = [j for i in lst_ext_motifs for j in i]\n",
    "        lst_non_ext_motifs = [\n",
    "            m for m in lst_motifs if m not in lst_all_ext_motifs]\n",
    "        lst_root_motifs = [el[0] for el in lst_ext_motifs]\n",
    "        lst_motifs_mask += lst_root_motifs+lst_non_ext_motifs\n",
    "        print('Root-motifs', lst_root_motifs)\n",
    "        print('Extended-motifs', lst_ext_motifs)\n",
    "        print('Non-extended motifs', lst_non_ext_motifs)\n",
    "        print('\\n')\n",
    "        \n",
    "    # Selecting the rows of the df_general where the occurrences\n",
    "    # belong only to the non redundant motifs.\n",
    "    df_general_non_redundant = df_general[df_general.motif.isin(\n",
    "        lst_motifs_mask)]\n",
    "    \n",
    "    return lst_motifs_mask, df_general_non_redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5068298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_occurrences_mots_of_CLUMPs(df_general_non_redundant):\n",
    "    \"\"\"count_all_occurrences_mots_of_CLUMPs\n",
    "       ------------------------------------\n",
    "       This function calculates all the occurrences of each CLUMP \n",
    "       in each dataset including multiple occurrences \n",
    "       of a motif in a sequence.\n",
    "       \n",
    "       Arguments:\n",
    "       df_general_non_redundant -- pandas dataframe where the occurrences\n",
    "       belong only to the non redundant motifs.\n",
    "       \n",
    "       Output:\n",
    "       motif_counts -- pandas dataframe with the number of\n",
    "                       occurrences of the CLUMP in the two \n",
    "                       datasets.\n",
    "       \n",
    "    \"\"\"\n",
    "    motifs_counts = pd.DataFrame(df_general_non_redundant.groupby(\n",
    "        ['CLUMP', 'dataset'])['occ'].sum())\n",
    "    motifs_counts = motifs_counts.reset_index()\n",
    "    motifs_counts = motifs_counts.pivot(\n",
    "        index='CLUMP', columns='dataset', values='occ')\n",
    "    motifs_counts = motifs_counts.rename_axis(None,axis=1)\n",
    "    motifs_counts = motifs_counts.reset_index()\n",
    "    \n",
    "    return motifs_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ba37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nb_seqs_containing_mots_of_CLUMPs(df_general_non_redundant):\n",
    "    \"\"\"count_nb_seqs_containing_mots_of_CLUMPs\n",
    "       ---------------------------------------\n",
    "       This function calculates how many sequences contain a \n",
    "       motif of a CLUMP, without considering if the motif is present\n",
    "       more than once in a sequence.\n",
    "       Hence how many sequences are found by the CLUMP, considering the\n",
    "       sequence only once.\n",
    "       \n",
    "       Arguments:\n",
    "       df_general_non_redundant -- pandas dataframe where the occurrences\n",
    "       belong only to the non redundant motifs.\n",
    "       \n",
    "       Output:\n",
    "       df_cnt_seq_per_cluster -- pandas dataframe with the number of\n",
    "                                 sequences found by the CLUMP in the\n",
    "                                 two datasets.\n",
    "       \n",
    "    \"\"\"\n",
    "    # Calculating how many sequences contain a motif of a CLUMP\n",
    "    # (how many sequences are found by the CLUMP, considering the\n",
    "    # sequence only once) without considering if the motif is present \n",
    "    # more than once in a sequence.\n",
    "    df_cnt_seq_per_cluster = df_general_non_redundant.groupby([\n",
    "        'CLUMP', 'seq_id', 'dataset']).size().reset_index(name='temporary')\n",
    "    df_cnt_seq_per_cluster = df_cnt_seq_per_cluster.drop(\n",
    "        columns = 'temporary')\n",
    "    df_cnt_seq_per_cluster = df_cnt_seq_per_cluster.drop_duplicates()\n",
    "    df_cnt_seq_per_cluster = df_cnt_seq_per_cluster.groupby(\n",
    "        ['CLUMP', 'dataset']).size().reset_index()\n",
    "    df_cnt_seq_per_cluster = df_cnt_seq_per_cluster.pivot(\n",
    "        index='CLUMP', columns='dataset', values = 0)\n",
    "    df_cnt_seq_per_cluster = df_cnt_seq_per_cluster.rename_axis(None,axis=1)\n",
    "    df_cnt_seq_per_cluster = df_cnt_seq_per_cluster.reset_index()\n",
    "    \n",
    "    return df_cnt_seq_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78bec44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occ_and_nb_seqs(df_clusters, df_general):\n",
    "    \"\"\"find_occ_and_nb_seqs\n",
    "       --------------------\n",
    "       This function finds the non redudant motifs from the \n",
    "       original df_clusters.\n",
    "       Then finds the subset of df_general where only the \n",
    "       non redundant motifs are considered.\n",
    "       Finally calculates the occurrences of the motifs of the CLUMPs \n",
    "       and the number of sequences found by the CLUMP. \n",
    "       (for more information about the two outputs, read doc of following\n",
    "       two functions:\n",
    "       count_all_occurrences_mots_of_CLUMPs()  \n",
    "       count_nb_seqs_containing_mots_of_CLUMPs()).\n",
    "       \n",
    "       Arguments:\n",
    "       df_clusters -- pandas dataframe of the motif and corresponding CLUMP.\n",
    "       df_general -- pandas dataframe with: motif, CLUMP, seq_id, occ, dataset.\n",
    "       \n",
    "       Output:\n",
    "       lst_motifs_mask -- list of non redundant motifs.\n",
    "       motif_counts -- pandas dataframe with the number of\n",
    "                       occurrences of the CLUMP in the two \n",
    "                       datasets.\n",
    "       df_cnt_seq_per_cluster -- pandas dataframe with the number of\n",
    "                                 sequences found by the CLUMP in the\n",
    "                                 two datasets.\n",
    "    \"\"\"\n",
    "    lst_motifs_mask, df_general_non_redundant = non_redundant_motifs(\n",
    "        df_clusters, df_general)\n",
    "    motif_counts = count_all_occurrences_mots_of_CLUMPs(\n",
    "        df_general_non_redundant)\n",
    "    df_cnt_seq_per_cluster = count_nb_seqs_containing_mots_of_CLUMPs(\n",
    "        df_general_non_redundant)\n",
    "    \n",
    "    return lst_motifs_mask, df_general_non_redundant, motif_counts, df_cnt_seq_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9539b93",
   "metadata": {},
   "source": [
    "# Test last 2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09424f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif</th>\n",
       "      <th>CLUMP</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>occ</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHWT</td>\n",
       "      <td>0</td>\n",
       "      <td>Minc3s00008g00574</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GHWT</td>\n",
       "      <td>0</td>\n",
       "      <td>Minc3s00736g16684</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHWT</td>\n",
       "      <td>0</td>\n",
       "      <td>Minc3s01051g20218</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GHWT</td>\n",
       "      <td>0</td>\n",
       "      <td>Minc3s01143g21148</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GHWT</td>\n",
       "      <td>0</td>\n",
       "      <td>Minc3s01152g21216</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>KCS</td>\n",
       "      <td>10</td>\n",
       "      <td>Minc3s01070g20414</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>KCS</td>\n",
       "      <td>10</td>\n",
       "      <td>Minc3s01536g24546</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>KCS</td>\n",
       "      <td>10</td>\n",
       "      <td>Minc3s02273g29198</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>KCS</td>\n",
       "      <td>10</td>\n",
       "      <td>Minc3s03208g33140</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>KCS</td>\n",
       "      <td>10</td>\n",
       "      <td>Minc3s05908g39009</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1815 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    motif  CLUMP             seq_id  occ   dataset\n",
       "0    GHWT      0  Minc3s00008g00574    1  positive\n",
       "1    GHWT      0  Minc3s00736g16684    1  positive\n",
       "2    GHWT      0  Minc3s01051g20218    1  positive\n",
       "3    GHWT      0  Minc3s01143g21148    1  positive\n",
       "4    GHWT      0  Minc3s01152g21216    1  positive\n",
       "..    ...    ...                ...  ...       ...\n",
       "682   KCS     10  Minc3s01070g20414    1  negative\n",
       "683   KCS     10  Minc3s01536g24546    1  negative\n",
       "684   KCS     10  Minc3s02273g29198    1  negative\n",
       "685   KCS     10  Minc3s03208g33140    1  negative\n",
       "686   KCS     10  Minc3s05908g39009    1  negative\n",
       "\n",
       "[1815 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_general = find_occurrences_of_mots_in_datasets(\n",
    "    df_clusters, pos_dict, neg_dict)\n",
    "df_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f789e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "CLUMP 0 :\n",
      "['HWT', 'WWS', 'WNT', 'CQY', 'FSL', 'NVY', 'WNS', 'HWF', 'GHWT', 'HWTQ', 'YSHS', 'FSVF', 'FTNS', 'GHWTQ']\n",
      "Root-motifs ['HWT']\n",
      "Extended-motifs [['HWT', 'GHWT', 'HWTQ', 'GHWTQ']]\n",
      "Non-extended motifs ['WWS', 'WNT', 'YSHS', 'CQY', 'FSVF', 'FSL', 'NVY', 'WNS', 'FTNS', 'HWF']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 1 :\n",
      "['PGNV', 'PTHP', 'YPSG', 'PKPF', 'PTPK', 'PKPY', 'PSPK', 'PKPN', 'PPPK', 'KPPG', 'RGIG', 'FPSP', 'KYPN', 'NGQP', 'PYPGQ', 'PYPSG', 'GYPSG', 'RYPSG', 'LYPSG', 'YYPGG', 'VYPSG', 'PYQSG']\n",
      "Root-motifs ['YPSG']\n",
      "Extended-motifs [['YPSG', 'PYPSG', 'GYPSG', 'RYPSG', 'LYPSG', 'VYPSG']]\n",
      "Non-extended motifs ['PGNV', 'PTHP', 'PYPGQ', 'PKPF', 'PTPK', 'YYPGG', 'PKPY', 'PSPK', 'PYQSG', 'PKPN', 'PPPK', 'KPPG', 'RGIG', 'FPSP', 'KYPN', 'NGQP']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 2 :\n",
      "['KHP', 'HGD', 'PKPK', 'PKYK', 'WKPK', 'KYKS', 'KQAQ', 'KTKL', 'PKAK', 'QEAF', 'AYKN', 'KMKG', 'FKAK', 'IKNN', 'KKIS', 'MDKF', 'VKSY']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['PKPK', 'PKYK', 'WKPK', 'KHP', 'KYKS', 'KQAQ', 'KTKL', 'PKAK', 'QEAF', 'HGD', 'AYKN', 'KMKG', 'FKAK', 'IKNN', 'KKIS', 'MDKF', 'VKSY']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 3 :\n",
      "['DAP', 'AEG', 'ADAE', 'ACGE', 'ATEN', 'DQAG', 'KDLE', 'MGVE', 'QEKL', 'SNEE', 'AEAD', 'AETD', 'DENL', 'NEAK', 'NEPL', 'TEAK', 'VDEG', 'CGEGE']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['ADAE', 'CGEGE', 'DAP', 'ACGE', 'ATEN', 'DQAG', 'KDLE', 'MGVE', 'QEKL', 'SNEE', 'AEG', 'AEAD', 'AETD', 'DENL', 'NEAK', 'NEPL', 'TEAK', 'VDEG']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 4 :\n",
      "['MIE', 'TML', 'TQLA', 'NLVG', 'AYAR', 'DIAK', 'NLTL', 'QLAK', 'AAIE', 'ILDN', 'RNLL', 'IANG', 'ILAN', 'QVAS', 'TILG', 'VEAV', 'VHAA']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['TQLA', 'NLVG', 'AYAR', 'DIAK', 'NLTL', 'QLAK', 'AAIE', 'ILDN', 'RNLL', 'MIE', 'IANG', 'ILAN', 'QVAS', 'TILG', 'TML', 'VEAV', 'VHAA']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 5 :\n",
      "['CGGG', 'FGGG', 'CGIGG', 'CGCCG', 'CGIGR', 'CGNCG', 'CGSGG', 'CCCGG', 'CGDGF', 'CGGGF', 'CNICG', 'CGGGY', 'CCCGF', 'CNGGG', 'CGCCA', 'CGDSG', 'CQNGG', 'CGGGA', 'CGKAG', 'CCSGY', 'PNPGG', 'PSPGG']\n",
      "Root-motifs ['CGGG']\n",
      "Extended-motifs [['CGGG', 'CGGGF', 'CGGGY', 'CGGGA']]\n",
      "Non-extended motifs ['CGIGG', 'CGCCG', 'CGIGR', 'CGNCG', 'CGSGG', 'CCCGG', 'CGDGF', 'CNICG', 'CCCGF', 'CNGGG', 'CGCCA', 'CGDSG', 'CQNGG', 'CGKAG', 'CCSGY', 'PNPGG', 'PSPGG', 'FGGG']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 6 :\n",
      "['EEER', 'KEEKK', 'EEEKK', 'KKEKK', 'KNEKK', 'KEERK', 'KEEIK', 'KEETK', 'GEEKK', 'KEEKG', 'EEGKK', 'EKEKK', 'EEERK', 'EEETK', 'GEGKK', 'KKETK', 'GEETK', 'KEETG', 'EKEKG', 'DEEKK', 'KEENK', 'KELKK', 'KEDKK', 'KDEKK', 'KEEEK', 'EEERG', 'KEEDK', 'KEESK', 'KEEKI', 'KEEKE']\n",
      "Root-motifs ['EEER']\n",
      "Extended-motifs [['EEER', 'EEERK', 'EEERG']]\n",
      "Non-extended motifs ['KEEKK', 'EEEKK', 'KKEKK', 'KNEKK', 'KEERK', 'KEEIK', 'KEETK', 'GEEKK', 'KEEKG', 'EEGKK', 'EKEKK', 'EEETK', 'GEGKK', 'KKETK', 'GEETK', 'KEETG', 'EKEKG', 'DEEKK', 'KEENK', 'KELKK', 'KEDKK', 'KDEKK', 'KEEEK', 'KEEDK', 'KEESK', 'KEEKI', 'KEEKE']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 7 :\n",
      "['ELIY', 'ILFS', 'FLIP', 'YVIL', 'IIYE', 'FSLFL', 'FSLEL', 'FLLFL', 'FKLFL', 'FSLSL', 'FSIFL', 'LSLFL', 'FLIFL', 'FLISL']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['FSLFL', 'FSLEL', 'FLLFL', 'FKLFL', 'FSLSL', 'FSIFL', 'LSLFL', 'FLIFL', 'FLISL', 'ELIY', 'ILFS', 'FLIP', 'YVIL', 'IIYE']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 8 :\n",
      "['THE', 'KTD', 'DKE', 'KDKK', 'KDKC', 'KDKM', 'KDCK', 'PKEK', 'EDKK', 'KDAK', 'KDMK', 'GDKK', 'KKPK', 'KDEK', 'TDKK', 'EEKK', 'RYDD', 'DEKT', 'KKEG', 'KRDD', 'QDVD', 'QKEE', 'RKEE', 'KEGKK', 'KKGKK']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['KEGKK', 'KDKK', 'KKGKK', 'KDKC', 'KDKM', 'KDCK', 'PKEK', 'EDKK', 'KDAK', 'KDMK', 'GDKK', 'KKPK', 'KDEK', 'TDKK', 'EEKK', 'RYDD', 'DEKT', 'KKEG', 'KRDD', 'QDVD', 'QKEE', 'RKEE', 'THE', 'KTD', 'DKE']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 9 :\n",
      "['CGIG', 'CVAF', 'IIAG', 'GGVI', 'CLIGG']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['CLIGG', 'CGIG', 'CVAF', 'IIAG', 'GGVI']\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "CLUMP 10 :\n",
      "['CK', 'TAC', 'RCP', 'KCT', 'RVC', 'NCD', 'NPD', 'KCS', 'VTDS', 'DSTL', 'TPDS', 'AKGS', 'NPTT', 'TASG']\n",
      "Root-motifs []\n",
      "Extended-motifs []\n",
      "Non-extended motifs ['TAC', 'RCP', 'KCT', 'VTDS', 'DSTL', 'RVC', 'CK', 'TPDS', 'AKGS', 'NCD', 'NPD', 'NPTT', 'TASG', 'KCS']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['HWT',\n",
       " 'WWS',\n",
       " 'WNT',\n",
       " 'YSHS',\n",
       " 'CQY',\n",
       " 'FSVF',\n",
       " 'FSL',\n",
       " 'NVY',\n",
       " 'WNS',\n",
       " 'FTNS',\n",
       " 'HWF',\n",
       " 'YPSG',\n",
       " 'PGNV',\n",
       " 'PTHP',\n",
       " 'PYPGQ',\n",
       " 'PKPF',\n",
       " 'PTPK',\n",
       " 'YYPGG',\n",
       " 'PKPY',\n",
       " 'PSPK',\n",
       " 'PYQSG',\n",
       " 'PKPN',\n",
       " 'PPPK',\n",
       " 'KPPG',\n",
       " 'RGIG',\n",
       " 'FPSP',\n",
       " 'KYPN',\n",
       " 'NGQP',\n",
       " 'PKPK',\n",
       " 'PKYK',\n",
       " 'WKPK',\n",
       " 'KHP',\n",
       " 'KYKS',\n",
       " 'KQAQ',\n",
       " 'KTKL',\n",
       " 'PKAK',\n",
       " 'QEAF',\n",
       " 'HGD',\n",
       " 'AYKN',\n",
       " 'KMKG',\n",
       " 'FKAK',\n",
       " 'IKNN',\n",
       " 'KKIS',\n",
       " 'MDKF',\n",
       " 'VKSY',\n",
       " 'ADAE',\n",
       " 'CGEGE',\n",
       " 'DAP',\n",
       " 'ACGE',\n",
       " 'ATEN',\n",
       " 'DQAG',\n",
       " 'KDLE',\n",
       " 'MGVE',\n",
       " 'QEKL',\n",
       " 'SNEE',\n",
       " 'AEG',\n",
       " 'AEAD',\n",
       " 'AETD',\n",
       " 'DENL',\n",
       " 'NEAK',\n",
       " 'NEPL',\n",
       " 'TEAK',\n",
       " 'VDEG',\n",
       " 'TQLA',\n",
       " 'NLVG',\n",
       " 'AYAR',\n",
       " 'DIAK',\n",
       " 'NLTL',\n",
       " 'QLAK',\n",
       " 'AAIE',\n",
       " 'ILDN',\n",
       " 'RNLL',\n",
       " 'MIE',\n",
       " 'IANG',\n",
       " 'ILAN',\n",
       " 'QVAS',\n",
       " 'TILG',\n",
       " 'TML',\n",
       " 'VEAV',\n",
       " 'VHAA',\n",
       " 'CGGG',\n",
       " 'CGIGG',\n",
       " 'CGCCG',\n",
       " 'CGIGR',\n",
       " 'CGNCG',\n",
       " 'CGSGG',\n",
       " 'CCCGG',\n",
       " 'CGDGF',\n",
       " 'CNICG',\n",
       " 'CCCGF',\n",
       " 'CNGGG',\n",
       " 'CGCCA',\n",
       " 'CGDSG',\n",
       " 'CQNGG',\n",
       " 'CGKAG',\n",
       " 'CCSGY',\n",
       " 'PNPGG',\n",
       " 'PSPGG',\n",
       " 'FGGG',\n",
       " 'EEER',\n",
       " 'KEEKK',\n",
       " 'EEEKK',\n",
       " 'KKEKK',\n",
       " 'KNEKK',\n",
       " 'KEERK',\n",
       " 'KEEIK',\n",
       " 'KEETK',\n",
       " 'GEEKK',\n",
       " 'KEEKG',\n",
       " 'EEGKK',\n",
       " 'EKEKK',\n",
       " 'EEETK',\n",
       " 'GEGKK',\n",
       " 'KKETK',\n",
       " 'GEETK',\n",
       " 'KEETG',\n",
       " 'EKEKG',\n",
       " 'DEEKK',\n",
       " 'KEENK',\n",
       " 'KELKK',\n",
       " 'KEDKK',\n",
       " 'KDEKK',\n",
       " 'KEEEK',\n",
       " 'KEEDK',\n",
       " 'KEESK',\n",
       " 'KEEKI',\n",
       " 'KEEKE',\n",
       " 'FSLFL',\n",
       " 'FSLEL',\n",
       " 'FLLFL',\n",
       " 'FKLFL',\n",
       " 'FSLSL',\n",
       " 'FSIFL',\n",
       " 'LSLFL',\n",
       " 'FLIFL',\n",
       " 'FLISL',\n",
       " 'ELIY',\n",
       " 'ILFS',\n",
       " 'FLIP',\n",
       " 'YVIL',\n",
       " 'IIYE',\n",
       " 'KEGKK',\n",
       " 'KDKK',\n",
       " 'KKGKK',\n",
       " 'KDKC',\n",
       " 'KDKM',\n",
       " 'KDCK',\n",
       " 'PKEK',\n",
       " 'EDKK',\n",
       " 'KDAK',\n",
       " 'KDMK',\n",
       " 'GDKK',\n",
       " 'KKPK',\n",
       " 'KDEK',\n",
       " 'TDKK',\n",
       " 'EEKK',\n",
       " 'RYDD',\n",
       " 'DEKT',\n",
       " 'KKEG',\n",
       " 'KRDD',\n",
       " 'QDVD',\n",
       " 'QKEE',\n",
       " 'RKEE',\n",
       " 'THE',\n",
       " 'KTD',\n",
       " 'DKE',\n",
       " 'CLIGG',\n",
       " 'CGIG',\n",
       " 'CVAF',\n",
       " 'IIAG',\n",
       " 'GGVI',\n",
       " 'TAC',\n",
       " 'RCP',\n",
       " 'KCT',\n",
       " 'VTDS',\n",
       " 'DSTL',\n",
       " 'RVC',\n",
       " 'CK',\n",
       " 'TPDS',\n",
       " 'AKGS',\n",
       " 'NCD',\n",
       " 'NPD',\n",
       " 'NPTT',\n",
       " 'TASG',\n",
       " 'KCS']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_motifs_mask, motifs_counts, df_cnt_seq_per_cluster = find_occ_and_nb_seqs(\n",
    "    df_clusters, df_general)\n",
    "lst_motifs_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ef6ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUMP</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>124</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>288</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLUMP  negative  positive\n",
       "0       0        81       110\n",
       "1       1        10       112\n",
       "2       2        36       133\n",
       "3       3        85       129\n",
       "4       4        73       119\n",
       "5       5        10        62\n",
       "6       6        25        85\n",
       "7       7         5        58\n",
       "8       8       124       190\n",
       "9       9         8        35\n",
       "10     10       288       168"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifs_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b96354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUMP</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>109</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>208</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLUMP  negative  positive\n",
       "0       0        72        54\n",
       "1       1        10        50\n",
       "2       2        30        58\n",
       "3       3        66        57\n",
       "4       4        69        53\n",
       "5       5        10        40\n",
       "6       6        20        28\n",
       "7       7         5        44\n",
       "8       8       109        76\n",
       "9       9         8        23\n",
       "10     10       208        95"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnt_seq_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75149349",
   "metadata": {},
   "source": [
    "# J1 and J2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422b30f",
   "metadata": {},
   "source": [
    "## J1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d4a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_J1(motifs_counts, neg_dset_feat, pos_dset_feat):\n",
    "    \"\"\"calculate_J1\n",
    "       ------------\n",
    "       This function calculates J1. Modified Jaccard Index with data of the \n",
    "       occurrences of the motifs of the CLUMPs.\n",
    "       \n",
    "       Arguments:\n",
    "       motif_counts -- pandas dataframe with the number of\n",
    "                       occurrences of the CLUMP in the two \n",
    "                       datasets.\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset\n",
    "                       \n",
    "       Output:\n",
    "       J1 -- pandas dataframe with the results of the J1\n",
    "    \"\"\"\n",
    "    motifs_counts['norm_negative'] = motifs_counts.negative/len(neg_dset_feat)\n",
    "    motifs_counts['norm_positive'] = motifs_counts.positive/len(pos_dset_feat)\n",
    "\n",
    "    ## J1\n",
    "    motifs_counts[\n",
    "        'jaccard_norm_1'\n",
    "    ]= motifs_counts.norm_negative/motifs_counts.norm_positive\n",
    "    J1 = pd.DataFrame(motifs_counts['jaccard_norm_1'])\n",
    "    \n",
    "    return J1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da428d31",
   "metadata": {},
   "source": [
    "## J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_J2(df_cnt_seq_per_cluster, neg_dset_feat, pos_dset_feat):\n",
    "    \"\"\"calculate_J2\n",
    "       ------------\n",
    "       This function calculates J2. Modified Jaccard Index with data of the \n",
    "       number of sequences found by a CLUMP.\n",
    "       \n",
    "       Arguments:\n",
    "       df_cnt_seq_per_cluster -- pandas dataframe with the number of\n",
    "                                 sequences found by the CLUMP in the\n",
    "                                 two datasets.\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset\n",
    "                       \n",
    "       Output:\n",
    "       J2 -- pandas dataframe with the results of the J2\n",
    "    \"\"\"\n",
    "    df_cnt_seq_per_cluster[\n",
    "        'norm_negative'] = df_cnt_seq_per_cluster.negative/len(\n",
    "        neg_dset_feat)\n",
    "    df_cnt_seq_per_cluster[\n",
    "        'norm_positive'] = df_cnt_seq_per_cluster.positive/len(\n",
    "        pos_dset_feat)\n",
    "\n",
    "    ## J2\n",
    "    df_cnt_seq_per_cluster[\n",
    "        'jaccard_norm_2'\n",
    "    ] = df_cnt_seq_per_cluster.norm_negative/df_cnt_seq_per_cluster.norm_positive\n",
    "    J2 = pd.DataFrame(df_cnt_seq_per_cluster['jaccard_norm_2'])\n",
    "    \n",
    "    return J2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbc1d1",
   "metadata": {},
   "source": [
    "## calculate_J1_and_J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afa4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_J1_and_J2(\n",
    "    motifs_counts, df_cnt_seq_per_cluster, neg_dset_feat, pos_dset_feat):\n",
    "    \"\"\"calculate_J1_and_J2\n",
    "       -------------------\n",
    "       This function calculates the J1 and J2. Two modified Jaccard Indexes.\n",
    "       (for more information about the input of the two indexes\n",
    "       please read doc of the two following functions:\n",
    "       calculate_J1()\n",
    "       calculate_J2())\n",
    "       \n",
    "       Arguments:\n",
    "       motif_counts -- pandas dataframe with the number of\n",
    "                       occurrences of the CLUMP in the two \n",
    "                       datasets.\n",
    "       df_cnt_seq_per_cluster -- pandas dataframe with the number of\n",
    "                                 sequences found by the CLUMP in the\n",
    "                                 two datasets.\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset.\n",
    "                        \n",
    "       Output:\n",
    "       df_jaccard_index -- pandas dataframe with results of\n",
    "                           calculation of 1-J1 and 1-J2.\n",
    "    \"\"\"\n",
    "    J1 = calculate_J1(motifs_counts, neg_dset_feat, pos_dset_feat)\n",
    "    J2 = calculate_J2(df_cnt_seq_per_cluster, neg_dset_feat, pos_dset_feat)\n",
    "    \n",
    "    # here we are calculating the values of 1 - jaccard\n",
    "    # since we want a score by maximization. With values to directly \n",
    "    # sum the ones of the CLUMP score\n",
    "    df_jaccard_index = pd.concat([J1, J2], axis = 1)\n",
    "    df_jaccard_index = 1 - df_jaccard_index\n",
    "    df_jaccard_index.insert(0, 'CLUMP', np.arange(0, len(df_jaccard_index)))\n",
    "\n",
    "    return df_jaccard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a51cd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUMP</th>\n",
       "      <th>jaccard_norm_1</th>\n",
       "      <th>jaccard_norm_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.760496</td>\n",
       "      <td>0.566330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.970960</td>\n",
       "      <td>0.934949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.911962</td>\n",
       "      <td>0.831766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.785686</td>\n",
       "      <td>0.623392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.800475</td>\n",
       "      <td>0.576558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.947540</td>\n",
       "      <td>0.918687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.904337</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>0.963039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.787730</td>\n",
       "      <td>0.533519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.925657</td>\n",
       "      <td>0.886869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.442424</td>\n",
       "      <td>0.287868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLUMP  jaccard_norm_1  jaccard_norm_2\n",
       "0       0        0.760496        0.566330\n",
       "1       1        0.970960        0.934949\n",
       "2       2        0.911962        0.831766\n",
       "3       3        0.785686        0.623392\n",
       "4       4        0.800475        0.576558\n",
       "5       5        0.947540        0.918687\n",
       "6       6        0.904337        0.767677\n",
       "7       7        0.971961        0.963039\n",
       "8       8        0.787730        0.533519\n",
       "9       9        0.925657        0.886869\n",
       "10     10        0.442424        0.287868"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_J1_and_J2(\n",
    "    motifs_counts, df_cnt_seq_per_cluster, neg_dset_feat, pos_dset_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee2581",
   "metadata": {},
   "source": [
    "# CLUMP_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66005f",
   "metadata": {},
   "source": [
    "## feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9332f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_weight(pos_dset_feat, neg_dset_feat, feature_lst):\n",
    "    \"\"\"feature_weight\n",
    "       --------------\n",
    "       This function calculates which features are significant.\n",
    "       To find that feature_weight uses the Mann-Whitney test, \n",
    "       which calculates the significance of the difference between \n",
    "       two datasets means (also for unpaired datasets), \n",
    "       and gives a p-value as part of the output.\n",
    "\n",
    "       null hypothesis (H0) : the difference between the two means \n",
    "       is not statistically significant. p-value >= 0.05\n",
    "       alternative hypothesis (H1): the difference between the two means \n",
    "       is statistically significant. p-value < 0.05 \n",
    "       \n",
    "       The features that result to be significant will receive a score.\n",
    "       Where the score = -log10(p-value)\n",
    "       \n",
    "       Arguments:\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset. \n",
    "       feature_lst -- list of features\n",
    "                        \n",
    "       Output:\n",
    "       dict_significant_features -- dictionary with significant\n",
    "                                    features as the keys and \n",
    "                                    the p-values as the values\n",
    "    \"\"\"\n",
    "    # Calculating the p-values\n",
    "    # Creating a list with the p-values in it\n",
    "    p_values_lst = []\n",
    "    m = len(feature_lst)\n",
    "    for i in range(m):\n",
    "        pos_values = pos_dset_feat.iloc[:, i]\n",
    "        pos_values = list(pos_values)\n",
    "        neg_values = neg_dset_feat.iloc[:, i]\n",
    "        neg_values = list(neg_values)\n",
    "        s, p = mannwhitneyu(pos_values, neg_values)\n",
    "        p_values_lst.append(p)\n",
    "    \n",
    "    # Creating a dictionary with the feature as the key and the p-value\n",
    "    # as the value.\n",
    "    # The zip iterator is useful to pair each feature with its p-value\n",
    "    # to then create the dictionary \n",
    "    zip_iterator = zip(feature_lst, p_values_lst)\n",
    "    dict_feat_p = dict(zip_iterator)\n",
    "    \n",
    "    # Creating a dictionary with the significant features their p-values\n",
    "    dict_significant_feat = {}\n",
    "    for feature, p_value in dict_feat_p.items():\n",
    "        if p_value < 0.05:\n",
    "            dict_significant_feat[feature] = p_value\n",
    "    # Sort features in order of significance\n",
    "    sign_feat = pd.DataFrame(dict_significant_feat, index = [0]).sort_values(\n",
    "        by = 0, axis = 1, ascending = False).transpose().to_dict()\n",
    "    dict_significant_features = sign_feat[0]\n",
    "    \n",
    "    return dict_significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51aa0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(pos_dset_feat, neg_dset_feat):\n",
    "    \"\"\"feature_selection\n",
    "       -----------------\n",
    "       This function calculates which features help to distinguish \n",
    "       the best the positive and the negative datasets (find an enrichment).\n",
    "       \n",
    "       Arguments:\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset.    \n",
    "\n",
    "                        \n",
    "       Output:\n",
    "       dict_feat_p_value_score_log -- dictionary of significant features\n",
    "                                      as keys and dictionaries as values.\n",
    "                                      These dictionaries contain information\n",
    "                                      of the the p-value and the score.\n",
    "       lst_signif_features -- list of significant features\n",
    "    \"\"\"\n",
    "    \n",
    "    # What are the candidate features?\n",
    "    pos_dset_feat = pos_dset_feat.drop(columns = ['seq_len'])\n",
    "    neg_dset_feat = neg_dset_feat.drop(columns = ['seq_len'])\n",
    "\n",
    "    feature_lst = []\n",
    "    for col in pos_dset_feat.columns:\n",
    "        feature_lst.append(col)\n",
    "    print('the number of candidate features is:', len(feature_lst))\n",
    "    \n",
    "    # Finding significant features and their p-values\n",
    "    dict_significant_features = feature_weight(\n",
    "        pos_dset_feat, neg_dset_feat, feature_lst)\n",
    "\n",
    "    # Creating a list of the significant features in order of significance\n",
    "    lst_signif_features = list(dict_significant_features)\n",
    "    print('the number of significant features is:', len(lst_signif_features))\n",
    "    print('significant features to calculate the CLUMP_score are:', \n",
    "          lst_signif_features)\n",
    "    \n",
    "    # Here we are creating a dictionary with the features and their p-values\n",
    "    # and scores from the -log10(p-value)\n",
    "    dict_feat_p_value_score_log = {} \n",
    "    for feature in lst_signif_features:\n",
    "        dict_feat_p_value_score_log[feature] = {}\n",
    "        dict_feat_p_value_score_log[feature][\n",
    "            'p-value'] = dict_significant_features[feature]\n",
    "        dict_feat_p_value_score_log[feature]['score'] = -math.log10(\n",
    "            dict_feat_p_value_score_log[feature]['p-value'])\n",
    "    \n",
    "    return lst_signif_features, dict_feat_p_value_score_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd4ab0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of candidate features is: 13\n",
      "the number of significant features is: 6\n",
      "significant features to calculate the CLUMP_score are: ['tiny', 'gravy', 'sheet', 'turn', 'helix', 'aliphatic']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tiny', 'gravy', 'sheet', 'turn', 'helix', 'aliphatic']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_signif_features, dict_feat_p_value_score_log = feature_selection(pos_dset_feat, neg_dset_feat)\n",
    "lst_signif_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9261bd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': {'p-value': 0.012607265122709778, 'score': 1.8993791141354173},\n",
       " 'gravy': {'p-value': 0.0019459942180807517, 'score': 2.710858454437325},\n",
       " 'sheet': {'p-value': 4.329771481105767e-06, 'score': 5.363535024458117},\n",
       " 'turn': {'p-value': 2.5991190933300425e-06, 'score': 5.585173820386985},\n",
       " 'helix': {'p-value': 2.768943582561357e-08, 'score': 7.557685892947779},\n",
       " 'aliphatic': {'p-value': 2.2651361264259894e-15, 'score': 14.644905693351284}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_feat_p_value_score_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8582db4",
   "metadata": {},
   "source": [
    "## Average_calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6b2850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_average_calculation(\n",
    "    neg_dset_feat, pos_dset_feat, lst_signif_features):\n",
    "    \"\"\"dataset_average_calculation\n",
    "       ---------------------------\n",
    "       This function calculates the average of each significant \n",
    "       feature for the two datasets.\n",
    "       \n",
    "       Arguments:\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset.\n",
    "       lst_signif_features -- list of significant features\n",
    "       \n",
    "       Output:\n",
    "       dict_pos_neg_means -- dictionary with the significant feature\n",
    "                             as the key and dictionaries as the values.\n",
    "                             The dictionaries contain information\n",
    "                             of the positive and negative average value\n",
    "                             for that feature.\n",
    "    \"\"\"\n",
    "    # Creating a list with the positive dataset means of the significant \n",
    "    # features\n",
    "    dict_pos_means = dict(pos_dset_feat.loc[:, lst_signif_features].mean())\n",
    "    # Creating a list with the negaive dataset means of the significant \n",
    "    # features\n",
    "    dict_neg_means = dict(neg_dset_feat.loc[:, lst_signif_features].mean())\n",
    "    \n",
    "    # Creating a dictionary with the features and their means\n",
    "    # for the positive and the negative datasets\n",
    "    dict_pos_neg_means = {} \n",
    "    for feature in lst_signif_features:\n",
    "        dict_pos_neg_means[feature] = {}\n",
    "        dict_pos_neg_means[feature]['pos_mean'] = dict_pos_means[feature]\n",
    "        dict_pos_neg_means[feature]['neg_mean'] = dict_neg_means[feature]\n",
    "    \n",
    "    return dict_pos_neg_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9737f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLUMPs_average_calculation(df_all_motifs_all_features, \n",
    "                               lst_signif_features):\n",
    "    \"\"\"CLUMPs_average_calculation\n",
    "       --------------------------\n",
    "       This function calculates the average of each significant\n",
    "       feature for the CLUMPs.\n",
    "    \n",
    "       Arguments:\n",
    "       df_all_motifs_all_features -- pandas dataframe with data of \n",
    "                                     feature values of the motifs.\n",
    "       lst_signif_features -- list of significant features\n",
    "                             \n",
    "       Output:\n",
    "       df_clusters_means -- pandas dataframe with data of average of the CLUMPs\n",
    "                            values for significant features.\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a list of the significant features\n",
    "    # and selecting subset of df_all_motifs_signif_features of\n",
    "    # values only of significant features\n",
    "    lst_signif_features.insert(0, 'CLUMP')\n",
    "    df_all_motifs_signif_features= df_all_motifs_all_features.loc[\n",
    "        :, lst_signif_features]\n",
    "    lst_signif_features.pop(0)\n",
    "    \n",
    "    # Calculating the averages\n",
    "    df_clusters_means = df_all_motifs_signif_features.groupby(\n",
    "    'CLUMP').mean().reset_index()\n",
    "    \n",
    "    return df_clusters_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd195aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_calculation(pos_dset_feat, neg_dset_feat, lst_signif_features,\n",
    "    df_all_motifs_all_features):\n",
    "    \"\"\"average_calculation\n",
    "       -------------------\n",
    "       This function calculates the average of each significant feature\n",
    "       for the CLUMPs and the two datasets.\n",
    "       \n",
    "       Arguments:\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset.\n",
    "       lst_signif_features -- list of significant features\n",
    "       df_all_motifs_all_features -- pandas dataframe with data of\n",
    "                                     feature values of the motifs.\n",
    "       \n",
    "       Output:\n",
    "       dict_pos_neg_means -- dictionary with the significant feature\n",
    "                             as the key and dictionaries as the values.\n",
    "                             The dictionaries contain information\n",
    "                             of the positive and negative average value\n",
    "                             for that feature.\n",
    "       df_clusters_means -- pandas dataframe with data of average of the CLUMPs\n",
    "                            values for significant features.\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculating the features' means in the positive and negative\n",
    "    # datasets\n",
    "    dict_pos_neg_means = dataset_average_calculation(\n",
    "        neg_dset_feat, pos_dset_feat, lst_signif_features)\n",
    "    \n",
    "    # Calculating the features' means of the CLUMPs\n",
    "    df_clusters_means = CLUMPs_average_calculation(\n",
    "        df_all_motifs_all_features, lst_signif_features)\n",
    "    \n",
    "    return dict_pos_neg_means, df_clusters_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b6fd87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': {'pos_mean': 0.2834034891909498, 'neg_mean': 0.26091760814193554},\n",
       " 'gravy': {'pos_mean': -0.4896251650801114, 'neg_mean': -0.3444228952769298},\n",
       " 'sheet': {'pos_mean': 0.23068133309964053, 'neg_mean': 0.25155914031139265},\n",
       " 'turn': {'pos_mean': 0.25494566616703496, 'neg_mean': 0.22734984235805394},\n",
       " 'helix': {'pos_mean': 0.27613178308669706, 'neg_mean': 0.30783187617867197},\n",
       " 'aliphatic': {'pos_mean': 0.24658259690574177,\n",
       "  'neg_mean': 0.2829720294472124}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pos_neg_means, df_clusters_means = average_calculation(pos_dset_feat, neg_dset_feat, lst_signif_features,\n",
    "    df_all_motifs_all_features)\n",
    "dict_pos_neg_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20a088e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUMP</th>\n",
       "      <th>tiny</th>\n",
       "      <th>gravy</th>\n",
       "      <th>sheet</th>\n",
       "      <th>turn</th>\n",
       "      <th>helix</th>\n",
       "      <th>aliphatic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>-0.736190</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.065476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.270455</td>\n",
       "      <td>-1.375000</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.179545</td>\n",
       "      <td>0.040909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.737745</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.132353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.352778</td>\n",
       "      <td>-1.231111</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.212037</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.721078</td>\n",
       "      <td>0.446078</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.539216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.345682</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.084091</td>\n",
       "      <td>0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-3.238333</td>\n",
       "      <td>0.411667</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.117857</td>\n",
       "      <td>2.289643</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.510714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>-3.034800</td>\n",
       "      <td>0.174667</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>-0.742262</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLUMP      tiny     gravy     sheet      turn     helix  aliphatic\n",
       "0       0  0.314286 -0.736190  0.023810  0.264286  0.425000   0.065476\n",
       "1       1  0.270455 -1.375000  0.009091  0.645455  0.179545   0.040909\n",
       "2       2  0.166667 -1.737745  0.132353  0.215686  0.176471   0.132353\n",
       "3       3  0.352778 -1.231111  0.494444  0.212037  0.083333   0.259259\n",
       "4       4  0.313725  0.721078  0.446078  0.147059  0.362745   0.539216\n",
       "5       5  0.788636  0.345682  0.027273  0.568182  0.084091   0.054545\n",
       "6       6  0.100000 -3.238333  0.411667  0.080000  0.020000   0.020000\n",
       "7       7  0.117857  2.289643  0.392857  0.135714  0.800000   0.510714\n",
       "8       8  0.112667 -3.034800  0.174667  0.056000  0.020000   0.020000\n",
       "9       9  0.570000  2.190000  0.140000  0.330000  0.430000   0.480000\n",
       "10     10  0.541667 -0.742262  0.077381  0.297619  0.059524   0.119048"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde69ce",
   "metadata": {},
   "source": [
    "## CLUMPs_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9a2f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLUMPs_sorting(\n",
    "    df_clusters_means, lst_signif_features, dict_pos_neg_means):\n",
    "    \"\"\"CLUMPs_sorting\n",
    "       --------------\n",
    "       This function sorts CLUMPs and gives them votes\n",
    "       in accordance with the following criteria.\n",
    "       \n",
    "        if average_positive_dataset - average_negative_dataset > 0:\n",
    "            for clusters with average > average_positive_dataset: \n",
    "                                        ranking from 1 to r\n",
    "                r = clusters in the right half\n",
    "            for clusters with average < average_positive_dataset: 0\n",
    "\n",
    "        if average_positive_dataset - average_negative_dataset < 0:\n",
    "            for clusters with average < average_positive_dataset: \n",
    "                                        ranking from 1 to r\n",
    "                r = clusters in the right half\n",
    "            for clusters with average > average_positive_dataset: 0\n",
    "        \n",
    "       Arguments: \n",
    "       df_clusters_means -- pandas dataframe with data of average of the CLUMPs\n",
    "                            values for significant features.\n",
    "       lst_signif_features -- list of significant features\n",
    "       dict_pos_neg_means -- dictionary with the significant feature\n",
    "                             as the key and dictionaries as the values.\n",
    "                             The dictionaries contain information\n",
    "                             of the positive and negative average value\n",
    "                             for that feature.\n",
    "       Output:\n",
    "       dict_feat_scores -- dictionary with the features as the keys\n",
    "                           and a list of the votes as the values.\n",
    "                           N.B. The votes in the lists are not sorted\n",
    "                           by CLUMP, but by vote.\n",
    "                           It will be in the function CLUMPs_voting\n",
    "                           that the votes will be assigned to the \n",
    "                           corresponding CLUMPs.\n",
    "        \n",
    "    \"\"\"\n",
    "    dict_feat_scores = {}\n",
    "    higher_scores = np.arange(1, len(df_clusters_means)+1)\n",
    "    \n",
    "    for feature in lst_signif_features:\n",
    "        df_clu_feature = pd.DataFrame(df_clusters_means.loc[:, feature])\n",
    "        lst_scores_feature = []\n",
    "        lst_higher_scores_feature = []\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if average_positive_dataset - average_negative_dataset > 0:\n",
    "        #    for clusters with average > average_positive_dataset: \n",
    "        #                                ranking from 1 to r\n",
    "        #        r = clusters in the right half\n",
    "        #    for clusters with average < average_positive_dataset: 0\n",
    "        if dict_pos_neg_means[feature][\n",
    "            'pos_mean'] - dict_pos_neg_means[feature]['neg_mean'] > 0:\n",
    "            # sorting ascendingly\n",
    "            df_clu_feature = df_clu_feature.sort_values(\n",
    "                ascending = True, by = feature)\n",
    "            \n",
    "            for i in range(len(df_clu_feature)):\n",
    "                \n",
    "                # if the feature average is greater than the positive\n",
    "                # dataset average\n",
    "                if float(df_clu_feature.iloc[i]) > dict_pos_neg_means[\n",
    "                    feature]['pos_mean']:\n",
    "                    feat_higher_score = i+1\n",
    "                    lst_higher_scores_feature.append(feat_higher_score)\n",
    "                    new_list_higher_scores_features = list(np.arange(\n",
    "                        1, len(lst_higher_scores_feature)+1))\n",
    "                    new_list_higher_scores_features\n",
    "                # if the feature average is less than the positive\n",
    "                # dataset average\n",
    "                else:\n",
    "                    feat_score = 0\n",
    "                    lst_scores_feature.append(feat_score)\n",
    "                    \n",
    "            lst_intermediate_scores = lst_scores_feature + new_list_higher_scores_features\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # if average_positive_dataset - average_negative_dataset < 0:\n",
    "        #    for clusters with average < average_positive_dataset: \n",
    "        #                                ranking from 1 to r\n",
    "        #        r = clusters in the right half\n",
    "        #    for clusters with average > average_positive_dataset: 0\n",
    "        else:\n",
    "            # sorting descendingly\n",
    "            df_clu_feature = df_clu_feature.sort_values(\n",
    "                ascending = False, by = feature)\n",
    "            \n",
    "            for i in range(len(df_clu_feature)):\n",
    "\n",
    "                # if the feature average is less than the positive\n",
    "                # dataset average\n",
    "                if float(df_clu_feature.iloc[i]) < dict_pos_neg_means[\n",
    "                    feature]['pos_mean']:\n",
    "                    feat_score = i+1\n",
    "                    lst_higher_scores_feature.append(feat_higher_score)\n",
    "                    new_list_higher_scores_features = list(np.arange(\n",
    "                        1, len(lst_higher_scores_feature)+1))\n",
    "                    new_list_higher_scores_features\n",
    "                # if the feature average is greater than the positive\n",
    "                # dataset average\n",
    "                else:\n",
    "                    feat_score = 0\n",
    "                    lst_scores_feature.append(feat_score)\n",
    "        \n",
    "            lst_intermediate_scores = lst_scores_feature + new_list_higher_scores_features\n",
    "            \n",
    "        dict_feat_scores[feature] = lst_intermediate_scores\n",
    "        \n",
    "    return dict_feat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67786e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feat_scores = CLUMPs_sorting(\n",
    "    df_clusters_means, lst_signif_features, dict_pos_neg_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c77dd",
   "metadata": {},
   "source": [
    "## CLUMPs_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2212739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLUMPs_voting(lst_signif_features, df_clusters_means, \n",
    "                  dict_pos_neg_means, dict_feat_scores):\n",
    "    \"\"\"CLUMPs_voting\n",
    "       -------------\n",
    "       This function assignes the calculated votes (CLUMPs_sorting)\n",
    "       to the corresponding CLUMPs.\n",
    "       \n",
    "       Arguments:\n",
    "       lst_signif_features -- list of significant features\n",
    "       df_clusters_means -- pandas dataframe with data of average of the CLUMPs\n",
    "                            values for significant features.\n",
    "       dict_pos_neg_means -- dictionary with the significant feature\n",
    "                             as the key and dictionaries as the values.\n",
    "                             The dictionaries contain information\n",
    "                             of the positive and negative average value\n",
    "                             for that feature.\n",
    "       dict_feat_scores -- dictionary with the features as the keys\n",
    "                           and a list of the votes as the values.\n",
    "                           N.B. The votes in the lists are not sorted\n",
    "                           by CLUMP, but by vote.\n",
    "                           It will be this function CLUMPs_voting that will \n",
    "                           assign the votes to the corresponding CLUMPs.\n",
    "       \n",
    "       Output: \n",
    "       final_votes -- pandas DataFrame with the vote of each CLUMP\n",
    "                      for each feature.\n",
    "    \"\"\"\n",
    "    lst_final_scores = []\n",
    "    for feature in lst_signif_features:\n",
    "        df_clu_feature = pd.DataFrame(df_clusters_means.loc[:, feature])\n",
    "        \n",
    "        # if average_positive_dataset - average_negative_dataset > 0:\n",
    "        if dict_pos_neg_means[feature][\n",
    "            'pos_mean'] - dict_pos_neg_means[feature]['neg_mean'] > 0:\n",
    "            # sort values of CLUMPs for that feature ascendingly\n",
    "            df_clu_feature = df_clu_feature.sort_values(ascending = True, by = feature)\n",
    "            df_clu_feature['score_'+feature] = dict_feat_scores[feature]\n",
    "            df_clu_feature = df_clu_feature.sort_index()\n",
    "            df_clu_feature = pd.DataFrame(df_clu_feature.iloc[:, 1])\n",
    "            df_clu_feature = df_clu_feature.rename(columns = {'score_'+feature : feature})\n",
    "            lst_clu_feature = list(df_clu_feature[feature])\n",
    "        \n",
    "        # if average_positive_dataset - average_negative_dataset < 0:\n",
    "        else : \n",
    "            # sort values of CLUMPs for that feature descendingly\n",
    "            df_clu_feature = df_clu_feature.sort_values(ascending = False, by = feature)\n",
    "            df_clu_feature['score_'+feature] = dict_feat_scores[feature]\n",
    "            df_clu_feature = df_clu_feature.sort_index()\n",
    "            df_clu_feature = pd.DataFrame(df_clu_feature.iloc[:, 1])\n",
    "            df_clu_feature = df_clu_feature.rename(columns = {'score_'+feature : feature})\n",
    "            lst_clu_feature = list(df_clu_feature[feature])\n",
    "        lst_final_scores.append(lst_clu_feature)\n",
    "\n",
    "    final_votes = pd.DataFrame(lst_final_scores).transpose()\n",
    "    final_votes.columns = lst_signif_features\n",
    "    final_votes= final_votes.transpose()\n",
    "    \n",
    "    return final_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c82511d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gravy</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheet</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turn</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helix</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aliphatic</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1   2   3   4   5   6   7   8   9   10\n",
       "tiny        2   0   0   3   1   6   0   0   0   5   4\n",
       "gravy       1   4   5   3   0   0   7   0   6   0   2\n",
       "sheet       6   7   3   0   0   5   0   0   1   2   4\n",
       "turn        1   5   0   0   0   4   0   0   0   3   2\n",
       "helix       0   1   2   4   0   3   6   0   7   0   5\n",
       "aliphatic   3   5   1   0   0   4   6   0   7   0   2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_votes = CLUMPs_voting(lst_signif_features, df_clusters_means, \n",
    "                            dict_pos_neg_means, dict_feat_scores)\n",
    "final_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088aa2a1",
   "metadata": {},
   "source": [
    "## CLUMPs_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a62e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLUMPs_scoring(\n",
    "    final_votes, lst_signif_features, dict_feat_p_value_score_log):\n",
    "    \"\"\"CLUMPs_scoring\n",
    "       --------------\n",
    "       This function multiplies the final_votes by the calculated\n",
    "       feature weights. Then sums the values of all the features \n",
    "       for each CLUMP. Finally, normalizes the result in a range from\n",
    "       0 to 1.\n",
    "       \n",
    "       Arguments: \n",
    "       final_votes -- pandas DataFrame with the vote of each CLUMP\n",
    "                      for each feature.\n",
    "       lst_signif_features -- list of significant features\n",
    "       dict_feat_p_value_score_log -- dictionary of significant features\n",
    "                                      as keys and dictionaries as values.\n",
    "                                      These dictionaries contain information\n",
    "                                      of the the p-value and the score.\n",
    "                                      \n",
    "       Output:\n",
    "       CLUMP_score_results -- pandas DataFrame with the normalized results of \n",
    "                              the CLUMP_scoring for each CLUMP\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extracting the scores of the significant features\n",
    "    feat_scores = []\n",
    "    for feature in lst_signif_features:\n",
    "        feat_scores.append(dict_feat_p_value_score_log[feature]['score'])\n",
    "    \n",
    "    # Multiplying the CLUMPs votes by the feature scores (feature weights)\n",
    "    df_clusters_weights_final = final_votes.mul(feat_scores, axis = 0)\n",
    "    \n",
    "    # Summing all the values of a CLUMP\n",
    "    CLUMP_score_results = pd.DataFrame(df_clusters_weights_final.sum()).rename(\n",
    "        columns = {0 : 'CLUMP_score'}).sort_values(\n",
    "        by = 'CLUMP_score', ascending = False)\n",
    "    \n",
    "    # Normalizing the results in a range from 0 to 1\n",
    "    CLUMP_score_results= (CLUMP_score_results - CLUMP_score_results.min()) / (\n",
    "        CLUMP_score_results.max() - CLUMP_score_results.min())\n",
    "    CLUMP_score_results.sort_index(inplace = True)\n",
    "    \n",
    "    return CLUMP_score_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e2109",
   "metadata": {},
   "source": [
    "## CLUMP_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "830ff92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLUMP_score(pos_dset_feat, neg_dset_feat, df_all_motifs_all_features):\n",
    "    \"\"\"CLUMP_score\n",
    "       -----------\n",
    "       This function calculates the CLUMP_score, which is \n",
    "       based on the averages of the CLUMPs' and of the two datasets' values\n",
    "       for a set of significant features. Significant features are those\n",
    "       for which the function finds an enrichment in one of the two datasets, \n",
    "       that is significant compared to the other.\n",
    "       \n",
    "       Arguments: \n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset. \n",
    "       df_all_motifs_all_features -- pandas dataframe with data of\n",
    "                                     feature values of the motifs.\n",
    "                        \n",
    "       Output:\n",
    "       CLUMP_score_results -- pandas DataFrame with the normalized results of \n",
    "                              the CLUMP_scoring for each CLUMP\n",
    "    \"\"\"\n",
    "    ## feature selection\n",
    "    lst_signif_features, dict_feat_p_value_score_log = feature_selection(\n",
    "        pos_dset_feat, neg_dset_feat)\n",
    "    \n",
    "    ## average calculation\n",
    "    dict_pos_neg_means, df_clusters_means = average_calculation(\n",
    "        pos_dset_feat, neg_dset_feat, lst_signif_features,\n",
    "        df_all_motifs_all_features)\n",
    "    \n",
    "    ## CLUMPs sorting\n",
    "    dict_feat_scores = CLUMPs_sorting(\n",
    "        df_clusters_means, lst_signif_features, dict_pos_neg_means)\n",
    "    \n",
    "    ## CLUMPs voting\n",
    "    final_votes = CLUMPs_voting(lst_signif_features, df_clusters_means, \n",
    "                            dict_pos_neg_means, dict_feat_scores)\n",
    "    \n",
    "    ## CLUMPs_scoring\n",
    "    CLUMP_score_results = CLUMPs_scoring(\n",
    "        final_votes, lst_signif_features, dict_feat_p_value_score_log)\n",
    "    \n",
    "    return CLUMP_score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "783889f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of candidate features is: 13\n",
      "the number of significant features is: 6\n",
      "significant features to calculate the CLUMP_score are: ['tiny', 'gravy', 'sheet', 'turn', 'helix', 'aliphatic']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUMP_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.335534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.248869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.800959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.859612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.208868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.636679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLUMP_score\n",
       "0      0.498234\n",
       "1      0.887315\n",
       "2      0.335534\n",
       "3      0.248869\n",
       "4      0.010728\n",
       "5      0.800959\n",
       "6      0.859612\n",
       "7      0.000000\n",
       "8      1.000000\n",
       "9      0.208868\n",
       "10     0.636679"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLUMP_score_results = CLUMP_score(pos_dset_feat, neg_dset_feat, df_all_motifs_all_features)\n",
    "CLUMP_score_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b62de9",
   "metadata": {},
   "source": [
    "# MOnSTER_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e408f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monster_ranking(MOnSTER_score_results):\n",
    "    \"\"\"monster_ranking\n",
    "       ---------------\n",
    "       This function ranks the CLUMPs based on the \n",
    "       the results of the MOnSTER_score calculation.\n",
    "       \n",
    "       Arguments:\n",
    "       MOnSTER_score_results -- pandas dataframe with the MOnSTER_score\n",
    "                                results.\n",
    "       Output:    \n",
    "       MOnSTER_score_results -- pandas dataframe with the MOnSTER_score\n",
    "                                results.\n",
    "    \"\"\"\n",
    "       \n",
    "    ranking = np.arange(1, len(MOnSTER_score_results)+1)\n",
    "    MOnSTER_score_results.sort_values(by = 'monster_score', ascending = False,\n",
    "                                      inplace= True)\n",
    "    MOnSTER_score_results['ranking'] = ranking\n",
    "    MOnSTER_score_results = MOnSTER_score_results.sort_index()\n",
    "    \n",
    "    return MOnSTER_score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69710f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOnSTER_score(\n",
    "    pos_dset_feat, neg_dset_feat, motifs_counts, df_cnt_seq_per_cluster, \n",
    "    df_clusters, df_all_motifs_all_features):\n",
    "    \"\"\"MOnSTER_score\n",
    "       -------------\n",
    "       This function calculates the MOnSTER score.\n",
    "       MOnSTER score is between 0 and 2.\n",
    "       To do that, it calculates the CLUMP_score (from 0 to 1), \n",
    "       J1 (from 0 to 1) and J2 (from 0 to 1), multiplies J1 and J2 by 0.5 \n",
    "       and then sums the 3 indexes.\n",
    "       \n",
    "       For further information about the calculation of these 3 indexes\n",
    "       please read doc of the following functions:\n",
    "       CLUMP_score()\n",
    "       calculate_J1_and_J2()\n",
    "       \n",
    "       Arguments:\n",
    "       pos_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the positive dataset.\n",
    "       neg_dset_feat -- pandas dataframe with data of feature values\n",
    "                        of the negative dataset.\n",
    "       motif_counts -- pandas dataframe with the number of\n",
    "                       occurrences of the CLUMP in the two \n",
    "                       datasets.\n",
    "       df_cnt_seq_per_cluster -- pandas dataframe with the number of\n",
    "                                 sequences found by the CLUMP in the\n",
    "                                 two datasets.\n",
    "       df_clusters -- pandas dataframe of the motif and corresponding CLUMP.\n",
    "       df_all_motifs_all_features -- pandas dataframe with data of\n",
    "                                     feature values of the motifs.\n",
    "\n",
    "       Output:\n",
    "       MOnSTER_score_results -- pandas dataframe with the MOnSTER_score\n",
    "                                results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculating the CLUMP_score\n",
    "    CLUMP_score_results = CLUMP_score(pos_dset_feat, neg_dset_feat, \n",
    "                                      df_all_motifs_all_features)\n",
    "    # Calculating J1 and J2\n",
    "    df_jaccard_index = calculate_J1_and_J2(\n",
    "        motifs_counts, df_cnt_seq_per_cluster, neg_dset_feat, pos_dset_feat)\n",
    "    \n",
    "    # Multiplying J1 and J2 by 0.5\n",
    "    df_jacc = df_jaccard_index.copy()\n",
    "    df_jacc['jaccard_norm_1'] = df_jacc['jaccard_norm_1']*0.5\n",
    "    df_jacc['jaccard_norm_2'] = df_jacc['jaccard_norm_2']*0.5\n",
    "    \n",
    "    # Calculating MOnSTER_score\n",
    "    MOnSTER_score_results = pd.concat([CLUMP_score_results, df_jacc], axis =1)\n",
    "    MOnSTER_score_results.drop(columns = 'CLUMP', inplace = True)\n",
    "    MOnSTER_score_results = pd.DataFrame(MOnSTER_score_results.sum(\n",
    "        axis =1)).rename(columns = {0 : 'monster_score'})\n",
    "    MOnSTER_score_results.insert(0, 'CLUMP', list(df_clusters.CLUMP.unique()))\n",
    "    \n",
    "    MOnSTER_score_results = monster_ranking(MOnSTER_score_results)\n",
    "    \n",
    "    return MOnSTER_score_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51d420e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of candidate features is: 13\n",
      "the number of significant features is: 6\n",
      "significant features to calculate the CLUMP_score are: ['tiny', 'gravy', 'sheet', 'turn', 'helix', 'aliphatic']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUMP</th>\n",
       "      <th>monster_score</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.161647</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.840269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.207398</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.953408</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.699245</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.734073</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.695619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.660625</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.115131</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.001825</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CLUMP  monster_score  ranking\n",
       "0       0       1.161647        6\n",
       "1       1       1.840269        1\n",
       "2       2       1.207398        5\n",
       "3       3       0.953408       10\n",
       "4       4       0.699245       11\n",
       "5       5       1.734073        2\n",
       "6       6       1.695619        3\n",
       "7       7       0.967500        9\n",
       "8       8       1.660625        4\n",
       "9       9       1.115131        7\n",
       "10     10       1.001825        8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOnSTER_score_results = MOnSTER_score(pos_dset_feat, neg_dset_feat, \n",
    "                                      motifs_counts, df_cnt_seq_per_cluster, \n",
    "                                      df_clusters, df_all_motifs_all_features)\n",
    "MOnSTER_score_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
